# 732A81 Project: Comparative Analysis of DistilBERT and Traditional Classifiers for Multi-Class News Classification
This repository contains the implementation of a text classification project comparing traditional machine learning methods (Naive Bayes and Logistic Regression) with advanced pre-trained models, specifically DistilBERT. The project uses the AG News dataset and explores the performance of these models under varying dataset sizes and configurations.

* "model_400.ipynb" file contains the models with training sample size 400
* "model_1000.ipynb" file contains the models with training sample size 1,000
* "model_5000.ipynb" file contains the models with training sample size 5,000
* "model_20000.ipynb" file contains the models with training sample size 20,000
* "full_baseline.ipynb" file contains the naive bayes classifier and logistic regression models with full dataset

The dataset is obtained from Kaggle: https://www.kaggle.com/datasets/amananandrai/ag-news-classification-dataset
